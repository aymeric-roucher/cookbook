{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient, login, HfApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c7eef272c441f4bbb712ff349a088c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(model=\"meta-llama/Meta-Llama-3-70B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.text_generation(\"Translate this text to French: Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image-to-image', 'text-to-image', 'feature-extraction', 'sentence-similarity', 'conversational', 'text-generation', 'summarization', 'text2text-generation', 'automatic-speech-recognition', 'document-question-answering', 'fill-mask', 'question-answering', 'text-to-audio', 'text-to-speech', 'image-classification', 'image-segmentation', 'image-to-text', 'object-detection', 'token-classification', 'translation', 'text-classification', 'visual-question-answering', 'zero-shot-classification'])\n",
      "['dandelin/vilt-b32-finetuned-vqa']\n",
      "['admruul/anything-v3.0', 'BatulMrakkan/snadeem', 'ByteDance/SDXL-Lightning', 'cagliostrolab/animagine-xl-3.0', 'cagliostrolab/animagine-xl-3.1', 'CompVis/stable-diffusion-v1-4', 'dataautogpt3/OpenDalleV1.1', 'dataautogpt3/ProteusV0.2', 'digiplay/AbsoluteReality_v1.8.1', 'digiplay/AingDiffusion7.5', 'digiplay/AM-mix1', 'digiplay/majicMIX_lux_v3', 'digiplay/majicMIX_realistic_v6', 'digiplay/MeinaPastel_v1', 'digiplay/pan04', 'digiplay/PerfectDeliberate-Anime_v1', 'digiplay/perfectlevel10', 'digiplay/Sweet-mix_v2.2_flat', 'digiplay/XtReMixUltimateMerge_v1.5', 'dreamlike-art/dreamlike-diffusion-1.0', 'dreamlike-art/dreamlike-photoreal-2.0', 'emilianJR/AnyLORA', 'etri-vilab/koala-700m', 'fluently/Fluently-XL-v2', 'gsdf/Counterfeit-V2.5', 'hakurei/waifu-diffusion', 'HenryZeng/cuhksz-yi-fu-shu-yuan', 'jayavibhav/anime-dreamlike', 'Joeythemonster/anything-midjourney-v-4-1', 'Koolchh/AnimeBoysXL-v1.0', 'Linaqruf/animagine-xl', 'Linaqruf/animagine-xl-2.0', 'Lykon/absolute-reality-1.6525', 'Lykon/dreamshaper-7', 'Lykon/dreamshaper-xl-turbo', 'Lykon/dreamshaper-xl-v2-turbo', 'MVRL/GeoSynth', 'nitrosocke/Arcane-Diffusion', 'nitrosocke/mo-di-diffusion', 'playgroundai/playground-v2-1024px-aesthetic', 'prompthero/openjourney', 'prompthero/openjourney-v4', 'prompthero/poolsuite-diffusion', 'runwayml/stable-diffusion-v1-5', 'segmind/Segmind-Vega', 'SG161222/Realistic_Vision_V1.4', 'ShibaDeveloper/olivia-v1.0', 'stabilityai/stable-diffusion-2', 'stabilityai/stable-diffusion-2-1', 'stabilityai/stable-diffusion-2-1-unclip', 'stablediffusionapi/animagine-xl-31', 'stablediffusionapi/anything-midjourney', 'stablediffusionapi/architecturerealmix', 'stablediffusionapi/better-than-hentai-xxl', 'stablediffusionapi/crystal-clear-xlv1', 'stablediffusionapi/duchaiten-real3d-nsfw-xl', 'stablediffusionapi/explicit-freedom-nsfw-wai', 'stablediffusionapi/landscapesupermix', 'stablediffusionapi/newrealityxl-global-nsfw', 'stablediffusionapi/newrealityxl-v2', 'stablediffusionapi/realistic-stock-photo', 'stablediffusionapi/sdxlceshi', 'stablediffusionapi/sdxxxl-v30-jan24', 'stablediffusionapi/strongly-styled', 'stablediffusionapi/wildcardx-xl-fusion', 'stablediffusionapi/zavychromaxlv3', 'TencentARC/PhotoMaker', 'UnfilteredAI/NSFW-gen', 'UnfilteredAI/NSFW-GEN-ANIME', 'UnfilteredAI/NSFW-gen-v2', 'WarriorMama777/OrangeMixs', 'Yntec/AbsoluteReality', 'Yntec/aMovieX', 'Yntec/Analog', 'Yntec/aPhotographicTrend', 'Yntec/CinematicReality', 'Yntec/CocaCola', 'Yntec/dosmixVAE', 'Yntec/DreamPhotoGASM', 'Yntec/DreamWorksRemix', 'Yntec/edgeOfRealism', 'Yntec/epiCPhotoGasm', 'Yntec/fennPhoto', 'Yntec/NostalgicLife', 'Yntec/Paramount', 'Yntec/photoMovieRealistic', 'Yntec/rainbowpatch', 'Yntec/realistic-vision-v12', 'Yntec/RealLife', 'Yntec/RetroLife', 'Yntec/sexyToons', 'Yntec/StableDiffusion768', 'Yntec/UberRealisticLegacy', 'Yntec/Voxel', 'Yntec/yabalMixTrue25D_v2_VAE']\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "print(InferenceClient().list_deployed_models().keys())\n",
    "print(InferenceClient().list_deployed_models()[\"visual-question-answering\"])\n",
    "print(InferenceClient().list_deployed_models()[\"text-to-image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hsramall/hsramall-70b-chat-placeholder']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generation_models = client.list_deployed_models()[\"text-generation\"]\n",
    "[model for model in text_generation_models if \"hsrama\" in model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelStatus(loaded=False, state='Loadable', compute_type={'gpu': {'gpu': 't4', 'count': 1}}, framework='diffusers')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InferenceClient().get_model_status(\"ByteDance/SDXL-Lightning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: mention cache!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": " (Request ID: IW5Wc21LLS-gZWXgFQYHR)\n\nBad request:\nModel type not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/venvs/cookbook/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/venvs/cookbook/lib/python3.11/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/ByteDance/SDXL-Lightning",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mInferenceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mByteDance/SDXL-Lightning\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA cat sitting on a table\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/cookbook/lib/python3.11/site-packages/huggingface_hub/inference/_client.py:1668\u001b[0m, in \u001b[0;36mInferenceClient.text_to_image\u001b[0;34m(self, prompt, negative_prompt, height, width, num_inference_steps, guidance_scale, model, **kwargs)\u001b[0m\n\u001b[1;32m   1666\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1667\u001b[0m         payload\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})[key] \u001b[38;5;241m=\u001b[39m value  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 1668\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-to-image\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bytes_to_image(response)\n",
      "File \u001b[0;32m~/venvs/cookbook/lib/python3.11/site-packages/huggingface_hub/inference/_client.py:242\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/venvs/cookbook/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:358\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m    355\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m     )\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(\u001b[38;5;28mstr\u001b[39m(e), response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mBadRequestError\u001b[0m:  (Request ID: IW5Wc21LLS-gZWXgFQYHR)\n\nBad request:\nModel type not found"
     ]
    }
   ],
   "source": [
    "InferenceClient(\"ByteDance/SDXL-Lightning\").text_to_image(\"A cat sitting on a table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cookbook",
   "language": "python",
   "name": "cookbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
